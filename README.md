### This Repository is a Fun Space to Work with the Open Data from Capella Space's S3 Bucket

#### Step 1: Get Data

    You will need to have the AWS-CLI. To see the years of datasets available run:

    ```aws s3 ls --no-sign-request s3://capella-open-data/data/```

    You should see the following folders:

        ```PRE 2020/
        PRE 2021/
        PRE 2022/
        PRE 2023/
        PRE 2024/
        PRE 2025/
        PRE tiledb/```

    Next let's look at some data from 2024

    aws s3 ls --no-sign-request --recursive s3://capella-open-data/data/2024/ | grep GEO | grep -i '\.tif$' | head -20 

    You should get this:

    2024-10-25 17:02:00 1245084289 data/2024/1/18/CAPELLA_C06_SM_GEO_HH_20240118050011_20240118050019/CAPELLA_C06_SM_GEO_HH_20240118050011_20240118050019.tif
    2024-10-25 20:40:04  563513412 data/2024/1/18/CAPELLA_C06_SM_GEO_HH_20240118050011_20240118050019/CAPELLA_C06_SM_GEO_HH_20240118050011_20240118050019_preview.tif
    2024-10-25 23:14:15  511201947 data/2024/1/21/CAPELLA_C06_SM_GEO_HH_20240121025802_20240121025806/CAPELLA_C06_SM_GEO_HH_20240121025802_20240121025806.tif
    2024-10-25 20:14:29  255243700 data/2024/1/21/CAPELLA_C06_SM_GEO_HH_20240121025802_20240121025806/CAPELLA_C06_SM_GEO_HH_20240121025802_20240121025806_preview.tif
    2024-10-25 16:50:01  267586118 data/2024/1/26/CAPELLA_C06_SS_GEO_HH_20240126194132_20240126194144/CAPELLA_C06_SS_GEO_HH_20240126194132_20240126194144.tif
    2024-10-25 20:02:27  117151773 data/2024/1/26/CAPELLA_C06_SS_GEO_HH_20240126194132_20240126194144/CAPELLA_C06_SS_GEO_HH_20240126194132_20240126194144_preview.tif
    2024-10-27 01:44:02  696280874 data/2024/1/31/CAPELLA_C10_SP_GEO_HH_20240131124434_20240131124509/CAPELLA_C10_SP_GEO_HH_20240131124434_20240131124509.tif
    2024-10-27 01:40:08  318674838 data/2024/1/31/CAPELLA_C10_SP_GEO_HH_20240131124434_20240131124509/CAPELLA_C10_SP_GEO_HH_20240131124434_20240131124509_preview.tif
    2024-10-27 01:09:24  367763792 data/2024/1/4/CAPELLA_C06_SP_GEO_HH_20240104015400_20240104015423/CAPELLA_C06_SP_GEO_HH_20240104015400_20240104015423.tif
    2024-10-25 17:24:32  174520582 data/2024/1/4/CAPELLA_C06_SP_GEO_HH_20240104015400_20240104015423/CAPELLA_C06_SP_GEO_HH_20240104015400_20240104015423_preview.tif
    2024-10-25 20:32:39  425449761 data/2024/1/6/CAPELLA_C06_SM_GEO_HH_20240106093858_20240106093901/CAPELLA_C06_SM_GEO_HH_20240106093858_20240106093901.tif
    2024-10-25 20:35:40  186330774 data/2024/1/6/CAPELLA_C06_SM_GEO_HH_20240106093858_20240106093901/CAPELLA_C06_SM_GEO_HH_20240106093858_20240106093901_preview.tif
    2024-10-25 22:55:53  541635575 data/2024/1/7/CAPELLA_C10_SP_GEO_HH_20240107170559_20240107170632/CAPELLA_C10_SP_GEO_HH_20240107170559_20240107170632.tif
    2024-10-25 20:11:30  241205817 data/2024/1/7/CAPELLA_C10_SP_GEO_HH_20240107170559_20240107170632/CAPELLA_C10_SP_GEO_HH_20240107170559_20240107170632_preview.tif
    2024-10-25 23:14:08  512279283 data/2024/1/8/CAPELLA_C09_SP_GEO_HH_20240108161822_20240108161849/CAPELLA_C09_SP_GEO_HH_20240108161822_20240108161849.tif
    2024-10-25 22:24:06  222263930 data/2024/1/8/CAPELLA_C09_SP_GEO_HH_20240108161822_20240108161849/CAPELLA_C09_SP_GEO_HH_20240108161822_20240108161849_preview.tif
    2024-10-25 17:20:14 1065100592 data/2024/10/1/CAPELLA_C09_SM_GEO_HH_20241001001135_20241001001151/CAPELLA_C09_SM_GEO_HH_20241001001135_20241001001151.tif
    2024-10-25 17:12:57  498397745 data/2024/10/1/CAPELLA_C09_SM_GEO_HH_20241001001135_20241001001151/CAPELLA_C09_SM_GEO_HH_20241001001135_20241001001151_preview.tif
    2024-10-26 01:31:56 1287013942 data/2024/10/1/CAPELLA_C13_SP_GEO_HH_20241001184147_20241001184220/CAPELLA_C13_SP_GEO_HH_20241001184147_20241001184220.tif
    2024-10-25 16:53:57  597481804 data/2024/10/1/CAPELLA_C13_SP_GEO_HH_20241001184147_20241001184220/CAPELLA_C13_SP_GEO_HH_20241001184147_20241001184220_preview.tif

    I am going to select one:

        aws s3 cp --no-sign-request \
    s3://capella-open-data/data/2024/1/26/CAPELLA_C06_SS_GEO_HH_20240126194132_20240126194144/ \
    data/raw/scene1/ --recursive




#### Step 2: Run make_tiles.py on CLI

    python make_tiles.py

#### Step 3: Split apart tiles to make a splits.json so we have data for training and then data for validation

    python make_split.py

#### Step 4: Train the convolutional neural network

    python train_cnn.py
    