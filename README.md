## This Repository is a Fun Space (pun intended) to Work with the Open Data from Capella Space's S3 Bucket

# Related to ```capella-sar-seg``` folder


#### Step 1: Get Data

    You will need to have the AWS-CLI. To see the years of datasets available run:

    ```aws s3 ls --no-sign-request s3://capella-open-data/data/```

    You should see the following folders:

        ```PRE 2020/
        PRE 2021/
        PRE 2022/
        PRE 2023/
        PRE 2024/
        PRE 2025/
        PRE tiledb/```

    Next let's look at some data from 2025


    aws s3 ls --no-sign-request --recursive s3://capella-open-data/data/2025/ \
    | grep CAPELLA_C11_SP_GEO_HH_20250320045730_20250320045802
 

    You should get this:

    2024-10-25 17:02:00 1245084289 data/2024/1/18/CAPELLA_C06_SM_GEO_HH_20240118050011_20240118050019/CAPELLA_C06_SM_GEO_HH_20240118050011_20240118050019.tif
    2024-10-25 20:40:04  563513412 data/2024/1/18/CAPELLA_C06_SM_GEO_HH_20240118050011_20240118050019/CAPELLA_C06_SM_GEO_HH_20240118050011_20240118050019_preview.tif
    2024-10-25 23:14:15  511201947 data/2024/1/21/CAPELLA_C06_SM_GEO_HH_20240121025802_20240121025806/CAPELLA_C06_SM_GEO_HH_20240121025802_20240121025806.tif
    2024-10-25 20:14:29  255243700 data/2024/1/21/CAPELLA_C06_SM_GEO_HH_20240121025802_20240121025806/CAPELLA_C06_SM_GEO_HH_20240121025802_20240121025806_preview.tif
    2024-10-25 16:50:01  267586118 data/2024/1/26/CAPELLA_C06_SS_GEO_HH_20240126194132_20240126194144/CAPELLA_C06_SS_GEO_HH_20240126194132_20240126194144.tif
    2024-10-25 20:02:27  117151773 data/2024/1/26/CAPELLA_C06_SS_GEO_HH_20240126194132_20240126194144/CAPELLA_C06_SS_GEO_HH_20240126194132_20240126194144_preview.tif
    2024-10-27 01:44:02  696280874 data/2024/1/31/CAPELLA_C10_SP_GEO_HH_20240131124434_20240131124509/CAPELLA_C10_SP_GEO_HH_20240131124434_20240131124509.tif
    2024-10-27 01:40:08  318674838 data/2024/1/31/CAPELLA_C10_SP_GEO_HH_20240131124434_20240131124509/CAPELLA_C10_SP_GEO_HH_20240131124434_20240131124509_preview.tif
    2024-10-27 01:09:24  367763792 data/2024/1/4/CAPELLA_C06_SP_GEO_HH_20240104015400_20240104015423/CAPELLA_C06_SP_GEO_HH_20240104015400_20240104015423.tif
    2024-10-25 17:24:32  174520582 data/2024/1/4/CAPELLA_C06_SP_GEO_HH_20240104015400_20240104015423/CAPELLA_C06_SP_GEO_HH_20240104015400_20240104015423_preview.tif
    2024-10-25 20:32:39  425449761 data/2024/1/6/CAPELLA_C06_SM_GEO_HH_20240106093858_20240106093901/CAPELLA_C06_SM_GEO_HH_20240106093858_20240106093901.tif
    2024-10-25 20:35:40  186330774 data/2024/1/6/CAPELLA_C06_SM_GEO_HH_20240106093858_20240106093901/CAPELLA_C06_SM_GEO_HH_20240106093858_20240106093901_preview.tif
    2024-10-25 22:55:53  541635575 data/2024/1/7/CAPELLA_C10_SP_GEO_HH_20240107170559_20240107170632/CAPELLA_C10_SP_GEO_HH_20240107170559_20240107170632.tif
    2024-10-25 20:11:30  241205817 data/2024/1/7/CAPELLA_C10_SP_GEO_HH_20240107170559_20240107170632/CAPELLA_C10_SP_GEO_HH_20240107170559_20240107170632_preview.tif
    2024-10-25 23:14:08  512279283 data/2024/1/8/CAPELLA_C09_SP_GEO_HH_20240108161822_20240108161849/CAPELLA_C09_SP_GEO_HH_20240108161822_20240108161849.tif
    2024-10-25 22:24:06  222263930 data/2024/1/8/CAPELLA_C09_SP_GEO_HH_20240108161822_20240108161849/CAPELLA_C09_SP_GEO_HH_20240108161822_20240108161849_preview.tif
    2024-10-25 17:20:14 1065100592 data/2024/10/1/CAPELLA_C09_SM_GEO_HH_20241001001135_20241001001151/CAPELLA_C09_SM_GEO_HH_20241001001135_20241001001151.tif
    2024-10-25 17:12:57  498397745 data/2024/10/1/CAPELLA_C09_SM_GEO_HH_20241001001135_20241001001151/CAPELLA_C09_SM_GEO_HH_20241001001135_20241001001151_preview.tif
    2024-10-26 01:31:56 1287013942 data/2024/10/1/CAPELLA_C13_SP_GEO_HH_20241001184147_20241001184220/CAPELLA_C13_SP_GEO_HH_20241001184147_20241001184220.tif
    2024-10-25 16:53:57  597481804 data/2024/10/1/CAPELLA_C13_SP_GEO_HH_20241001184147_20241001184220/CAPELLA_C13_SP_GEO_HH_20241001184147_20241001184220_preview.tif

I know I want to look at the Shanghai dataset so I will download this via the AWS-CLI:
    
    mkdir -p data/raw/scene_shanghai
    aws s3 cp --no-sign-request \
    s3://capella-open-data/data/2025/3/20/CAPELLA_C11_SP_GEO_HH_20250320045730_20250320045802/ \
    data/raw/scene_shanghai/ --recursive

![Shanghai Data](https://github.com/kllewers/Capella_Space_Dabbling/blob/main/Shanghai_data.png) 


#### Side Quest: A quick analysis and understanding the data coming to you a little more

Synthetic Aperture Radar (SAR) data comes in different “flavors,” and knowing which one you’re looking at is critical. In the Capella data products, you will often find both a **full GEO TIFF** and a **preview TIFF**. While both might appear as grayscale images, they are fundamentally different in how they are generated and what they can be used for.

---

### **1. The Preview TIFF**

The `…_preview.tif` is an **8-bit display-scaled quicklook image** generated by Capella.

* It has already been **contrast-stretched** and tone-mapped for human viewing.
* Pixel values are no longer proportional to physical radar backscatter.
* Great for quick visualization in GIS, web maps, or reports.
* **Not suitable for quantitative analysis** — the physical meaning of the values has been lost.

---

### **2. The Full GEO TIFF**

The `…_GEO_… .tif` file is the **radiometrically calibrated product** (e.g., sigma nought).

* Stores pixel values as **digital numbers (DNs)** proportional to calibrated radar backscatter.
* Contains the full dynamic range of the radar return.
* Suitable for:

  * **Multi-temporal analysis** (change detection)
  * **Land cover classification**
  * **Feature detection** (ships, urban areas, etc.)
  * **Multi-polarization analysis** (HH, HV, VV, VH)
  * **PCA or other statistical transformations**

---

### **3. Why Convert to dB**

SAR scattering spans **orders of magnitude**, so we almost always convert to **decibels (dB)** using the formula:

$$
\text{dB} = 10 \log_{10}(\text{value})
$$

The advantages are:

* **Dynamic range compression** — bright and dark features can be seen together.
* **Standardized interpretation** — SAR analysts talk in dB:

  * Urban areas: \~ +10 dB
  * Forest: \~ -5 dB
  * Water: \~ -20 dB
* Easier to set consistent visualization thresholds across scenes and dates.

---

### **4. Summary Table**

| Preview TIFF (8-bit)     | Full GEO TIFF (UInt16 → dB) |
| ------------------------ | --------------------------- |
| Already display-scaled   | Radiometrically calibrated  |
| No physical meaning      | Physical backscatter values |
| Quick visualization only | Analysis, comparison, PCA   |
| Contrast stretch applied | Requires dB scaling         |

---

### **5. Visual Comparison**

Below is a side-by-side comparison between the **preview TIFF** and the **full GEO TIFF (converted to dB)** from the same scene:

This is the preview which looks extremely noisy and almost binary:

![Preview](https://github.com/kllewers/Capella_Space_Dabbling/blob/main/Shanghai_data_preview.png)
 
This is the geotiff which looks much more crisp and you can even detect a few potential anomalies in the water:

![Geotiff](https://github.com/kllewers/Capella_Space_Dabbling/blob/main/Shanghai_data_geotiff.png)

---

This difference is why **starting with the GEO TIFF and converting to dB is essential** for any scientific or quantitative work. Using the preview TIFF for analysis is like using a JPEG photo of a graph instead of the original spreadsheet — it might look nice, but the numbers are gone.


#### Step 2: Run make_tiles.py on CLI

This dataset is massive and since I am running it on my local machine I will not be cross referencing/masking it with an OSM mask like I normally would. If was submitting the job to an HPC via slurm or leveraging an EC2 instance, I would do this.

    python <basepath>/make_tiles.py

#### Step 3: Split apart tiles to make a splits.json so we have data for training and then data for validation

    python <basepath>/make_split.py

#### Step 4: Train the convolutional neural network

Once again, this is being done locally on a Mac so there is some corner cutting (ie programmatically putting in the early drop off if there is not much difference between epochs, limiting how much is used for testing and validation, defining an ROI, taking out some augmenting, shamefully low number of epochs, etc). Either way, it's going to take 5-ever to run locally (~2hrs with this extremely paired down version found in capella-sar-seg/scripts/local_proofofconcept_train_cnn.py). Some say it's still running to this day #RIP

    python <basepath>/train_cnn.py

#### Step 5: Visualize the predictions made by the Neural Net. 

    python <basepath>/visualize_predictions.py


#### Results: I cannot stress enough that the model with its current amount of epochs and samples used is way way way less than ideal (some may say terrible). This is due to local computing and time constraints, BUT this is a good place to start for learning how to set up this project. Additionally, you can use a more robust workflow locally if you have time and don't need to use your computer for other computationally intensive tasks or if you want to try parallelization, I like to use dask (https://www.dask.org/). I also used the preview instead of the full GEOTIFF which was also a bad idea, but sometime you just gotta get that Proof of Concept a-goin...


#### For the Visual Learners (like me) here is a simplied ASCII-style diagram of the flow:

```
+-------------------------+
|  Capella Open Data (S3) |
|   GEO GeoTIFF + JSON    |
+-----------+-------------+
            |
            v
+-------------------------+
|   make_tiles.py         |
|  - Read SAR intensity   |
|  - Convert to dB        |
|  - Normalize [0,1]      |
|  - Download OSM bldgs   | <--- not doing in this specific analysis but would usually
|  - Rasterize masks      | <--- not doing in this specific analysis but would usually
+-----------+-------------+
            |
            v
+-------------------------+
|  data/tiles/            |
|   images/  -> .npy (SAR)|
|   masks/   -> .npy (GT) |
+-----------+-------------+
            |
            v
+-------------------------+
|  make_split.py          |
|  -> splits.json         |
|     train / val IDs     |
+-----------+-------------+
            |
            v
+-------------------------+
|  train_cnn.py           |
|  - U-Net + MobileNetV3  |
|  - Semantic Segmentation|
|  - Save best weights    |
+-----------+-------------+
            |
            v
+-------------------------+
|  visualize_predictions  |
|  - Load model           |
|  - SAR tile -> mask     |
|  - Display side-by-side |
+-------------------------+
```


# Related to ```capella-gee-sentinel-SAR``` folder


# Related to ```capella-gbif``` folder